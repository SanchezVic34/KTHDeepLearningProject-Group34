{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hr78EkAY-FFg"
   },
   "source": [
    "# Royal Institute of Technology - KTH\n",
    "# DD2424 - Deep Learning of Data Science.\n",
    "Project edited by Victor Sanchez - 19980429-T517.\n",
    "\n",
    "\n",
    "Training of a model using a collection of piano MIDI files from the [MAESTRO dataset](https://magenta.tensorflow.org/datasets/maestro). \n",
    "\n",
    "This file is a developped version of the tutorial [Music generation with an RNN](https://www.tensorflow.org/text/tutorials/music_generation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import *\n",
    "reset_keras()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FzIbfb-Ikgg7"
   },
   "source": [
    "## Download the Maestro dataset & Creation of the training dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path('data/maestro-v2.0.0')\n",
    "download_dataset(data_dir)\n",
    "\n",
    "filenames = generate_filename(data_dir)\n",
    "print('The dataset contains ' + str(len(filenames)) + ' MIDI files:')\n",
    "\n",
    "key_order = ['pitch', 'step', 'duration']\n",
    "\n",
    "nb_of_file_input = 1\n",
    "\n",
    "batch_size = 64\n",
    "seq_length = 8\n",
    "train_ds, list_file_in_dataset, nb_notes = dataset_generator_maestro(key_order, filenames, seq_length, batch_size, nb_files = nb_of_file_input, random_file = True, display_dataset_info = False, display_sequence_info = False)\n",
    "\n",
    "\n",
    "print('\\n the dataset generated has the following characteristics :')\n",
    "print(\"\\n\",train_ds.element_spec)\n",
    "\n",
    "midi_file_of_dataset = midi_to_notes(list_file_in_dataset[0])\n",
    "for i in range(1, nb_of_file_input):\n",
    "    midi_file_of_dataset_temporary = midi_to_notes(list_file_in_dataset[i])\n",
    "    midi_file_of_dataset = pd.concat([midi_file_of_dataset,midi_file_of_dataset_temporary], ignore_index=True)\n",
    "#print(\"\\n piano roll original\")\n",
    "#plot_piano_roll(midi_file_of_dataset,'original')\n",
    "\n",
    "#print(\"\\n distribution of original\")\n",
    "#plot_distributions(midi_file_of_dataset, 'original')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>DISCLAIMER: </font> Before each training seesion, restart the kernal of your notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of dataset with given file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_audio = 'data/other/pachelbel_canon.midi'\n",
    "# key_order = ['pitch', 'step', 'duration']\n",
    "# nb_of_file_input = 1\n",
    "# batch_size = 64\n",
    "# seq_length = 8\n",
    "# train_ds, nb_notes = dataset_generator_with_file(key_order, file_audio, seq_length, batch_size, display_dataset_info = False, display_sequence_info = False)\n",
    "# print(\"\\n\",train_ds.element_spec)\n",
    "\n",
    "# # print(\"\\n piano roll original\")\n",
    "# # plot_piano_roll(midi_to_notes(file_audio),'Original')\n",
    "# # print(\"\\n distribution of original\")\n",
    "# # plot_distributions(midi_to_notes(file_audio), 'Original')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jutzynyqX_GC"
   },
   "source": [
    "Remark on representation of a note :\n",
    "When training the model: `pitch`, `step` and `duration`. The pitch is the perceptual quality of the sound as a MIDI note number. \n",
    "The `step` is the time elapsed from the previous note or start of the track.\n",
    "The `duration` is how long the note will be playing in seconds and is the difference between the note end and note start times. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-71LPvjubOSO"
   },
   "source": [
    "It seems easier to interpret the note names rather than the pitches, so the function below is used to convert from the numeric pitch values to note names. \n",
    "The note name shows the type of note, accidental and octave number\n",
    "(e.g. C#4). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sj9SXRCjt3I7"
   },
   "source": [
    "The training of the model is made on batches of sequences of notes. Each example consists of a sequence of notes as the input features, and next note as the label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2xDX5pVkegrv"
   },
   "source": [
    "Notes for users :\n",
    "Set the sequence length for each example. Experiment with different lengths (e.g. 50, 100, 150) to see which one works best for the data, or use [hyperparameter tuning](https://www.tensorflow.org/tutorials/keras/keras_tuner). The size of the vocabulary (`vocab_size`) is set to 128 representing all the pitches supported by `pretty_midi`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWZmfkshqP8G"
   },
   "source": [
    "## Create and train a model with single hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-26T08:11:35.270381Z",
     "iopub.status.busy": "2022-01-26T08:11:35.268129Z",
     "iopub.status.idle": "2022-01-26T08:11:35.529073Z",
     "shell.execute_reply": "2022-01-26T08:11:35.525929Z"
    },
    "id": "kNaVWcCzAm5V"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.005\n",
    "type_RNN = \"LSTM\" # or \"RNNSimple\"\n",
    "type_optimizer = \"Adam\" # or \"Adagrad\" or \"RMSProp\"\n",
    "nb_neurons = 128\n",
    "nb_epochs = 5\n",
    "model = Network_init(seq_length, learning_rate, type_RNN, type_optimizer, nb_neurons)\n",
    "\n",
    "title = \"seq_length=\"+str(seq_length)+\"_learning_rate=\"+str(learning_rate)+\"_nb_epochs=\"+str(nb_epochs)+\"_batch_size=\"+str(batch_size)+\"_type_RNN=\"+type_RNN+\"_type_optimizer=\"+type_optimizer+\"_nb_of_file_input=\"+str(nb_of_file_input)+\"_nb_units=\"+str(nb_neurons)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDL0Jypt3eU5"
   },
   "source": [
    "Note for users : Testing the `model.evaluate` function, you can see that the `pitch` loss is significantly greater than the `step` and `duration` losses. \n",
    "Note that `loss` is the total loss computed by summing all the other losses and is currently dominated by the `pitch` loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a model with multiple hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rate = 0.005\n",
    "# type_RNN = \"LSTM\" # or \"RNNSimple\" or \"GRU\"\n",
    "# type_optimizer = \"Adam\" # or \"Adagrad\" or \"Adam\"\n",
    "# nb_epochs = 5\n",
    "# nodes = [128,128]\n",
    "# \"\"\"\n",
    "# if len(nodes) == 1:\n",
    "#     model = Network_init(seq_length, learning_rate, type_RNN, type_optimizer, nb_neurons = nodes[0])\n",
    "# else:\n",
    "#     model = Network_init_multi_layers(seq_length, learning_rate, nodes, type_RNN, type_optimizer)\n",
    "# \"\"\"\n",
    "# model = Network_init_test(seq_length, learning_rate, nodes, type_RNN, type_optimizer)\n",
    "# #model = Network_init(seq_length, learning_rate, type_RNN, type_optimizer, nb_neurons = nodes[0])\n",
    "# #model = Network_init_multi_layers(seq_length, learning_rate, nodes, type_RNN, type_optimizer)\n",
    "\n",
    "# nb_epochs = 5\n",
    "# title = \"seq_length=\"+str(seq_length)+\"_learning_rate=\"+str(learning_rate)+\"_nb_epochs=\"+str(nb_epochs)+\"_batch_size=\"+str(batch_size)+\"_type_RNN=\"+type_RNN+\"_type_optimizer=\"+type_optimizer+\"_nb_of_file_input=\"+str(nb_of_file_input)+\"_nb_units=\"+str(nodes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SJbn7HZgfosr"
   },
   "source": [
    "## Training of the generated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-26T08:11:43.596659Z",
     "iopub.status.busy": "2022-01-26T08:11:43.595989Z",
     "iopub.status.idle": "2022-01-26T08:11:43.597991Z",
     "shell.execute_reply": "2022-01-26T08:11:43.597584Z"
    },
    "id": "uQA_rwKEgPjp"
   },
   "outputs": [],
   "source": [
    "\n",
    "history = train_network(model, train_ds, nb_epochs)\n",
    "plotting_result(history, title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aPWI94lQ8uQA"
   },
   "source": [
    "## Prediction of notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wbaoiy4Hf-n5"
   },
   "source": [
    "We first provide a starting sequence of notes. The function below generates one note from a sequence of notes. \n",
    "\n",
    "For note pitch, it draws a sample from softmax distribution of notes produced by the model, and does not simply pick the note with the highest probability.\n",
    "Always picking the note with the highest probability would lead to repetitive sequences of notes being generated.\n",
    "\n",
    "The `temperature` parameter can be used to control the randomness of notes generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W64K-EX3hxU_"
   },
   "source": [
    "Now generate some notes. You can play around with temperature and the starting sequence in `next_notes` and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_sample = pretty_midi.PrettyMIDI(list_file_in_dataset[0])\n",
    "raw_notes = midi_to_notes(list_file_in_dataset[0])\n",
    "#print('Number of instruments:', len(pm_sample.instruments))\n",
    "instrument = pm_sample.instruments[0]\n",
    "instrument_name = pretty_midi.program_to_instrument_name(instrument.program)\n",
    "\n",
    "vocab_size = 128\n",
    "temperature = 0.9\n",
    "num_predictions = 100 #int(nb_notes)\n",
    "\n",
    "title_new = title+\"_temperature=\"+str(temperature)\n",
    "\n",
    "generated_notes, out_pm = predict_notes(raw_notes, seq_length, title_new,  vocab_size, instrument_name, temperature, model, export_prediciton = True, num_predictions = num_predictions)\n",
    "\n",
    "\n",
    "# print(\"\\n piano roll predicted\")\n",
    "plot_piano_roll(generated_notes, title_new)\n",
    "\n",
    "# print(\"\\n distribution of estimated\")\n",
    "# plot_distributions(generated_notes, title)\n",
    "plot_multiple_distributions(midi_file_of_dataset, generated_notes, title_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction of a single audio for multiple file data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pm_sample = pretty_midi.PrettyMIDI(list_file_in_dataset[0])\n",
    "# raw_notes = midi_to_notes(list_file_in_dataset[0])\n",
    "# #print('Number of instruments:', len(pm_sample.instruments))\n",
    "# instrument = pm_sample.instruments[0]\n",
    "# instrument_name = pretty_midi.program_to_instrument_name(instrument.program)\n",
    "\n",
    "# vocab_size = 128\n",
    "# temperature = 1\n",
    "# num_predictions = len(raw_notes)\n",
    "\n",
    "# #title_new = title+\"_temperature=\"+str(temperature)\n",
    "# title_new = title\n",
    "# generated_notes, out_pm = predict_notes(raw_notes, seq_length, title_new,  vocab_size, instrument_name, temperature, model, export_prediciton = True, num_predictions = num_predictions)\n",
    "\n",
    "\n",
    "# # print(\"\\n piano roll predicted\")\n",
    "# plot_piano_roll(generated_notes, title_new)\n",
    "\n",
    "\n",
    "# midi_file_of_dataset_first_file = midi_to_notes(list_file_in_dataset[0])\n",
    "# # print(\"\\n distribution of estimated\")\n",
    "# # plot_distributions(generated_notes, title)\n",
    "# plot_multiple_distributions(midi_file_of_dataset_first_file, generated_notes, title_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction of personnal audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pm_sample = pretty_midi.PrettyMIDI(file_audio)\n",
    "# raw_notes_perso = midi_to_notes(file_audio)\n",
    "# #print('Number of instruments:', len(pm_sample.instruments))\n",
    "# instrument = pm_sample.instruments[0]\n",
    "# instrument_name = pretty_midi.program_to_instrument_name(instrument.program)\n",
    "\n",
    "# vocab_size = 128\n",
    "# temperature = 0.3\n",
    "# num_predictions = nb_notes\n",
    "# title_perso = title\n",
    "# generated_notes, out_pm = predict_notes(raw_notes_perso, seq_length, title_perso,  vocab_size, instrument_name, temperature, model, export_prediciton = True, num_predictions = nb_notes)\n",
    "\n",
    "# #print(\"\\n Play the generated music\")\n",
    "# #display_audio(out_pm)\n",
    "\n",
    "# print(\"\\n piano roll original\")\n",
    "# plot_piano_roll(midi_to_notes(file_audio),title_perso)\n",
    "# print(\"\\n piano roll predicted\")\n",
    "# plot_piano_roll(generated_notes, title_perso)\n",
    "\n",
    "# print(\"\\n distribution of original\")\n",
    "# plot_distributions(midi_to_notes(file_audio), title_perso)\n",
    "\n",
    "# print(\"\\n distribution of estimated\")\n",
    "# plot_distributions(generated_notes, title_perso)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "music_generation.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "69e300a96e0de3ea60afab7dfbc4623c7a83f932318d04f8505ecde86115a198"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('WORK')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
